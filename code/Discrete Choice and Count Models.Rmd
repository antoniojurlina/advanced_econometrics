---
title: "Discrete Choice and Count Models"
author: "Antonio Jurlina"
date: "4/19/2021"
output: pdf_document
geometry: margin=1in
---

```{r setup, include=FALSE}
#-------- packages --------
library(tidyverse)
library(knitr)
```

##### **Problem 1.**

Recall that the choice probability under the nested logit model takes the form,

$$P_{ij}=P_{iB_k}\times P_{ij|B_k}$$
where $P_{iB_k}$ denotes the probability of person *i* choosing nest *k*


$$P_{iB_k}=\frac{e^{W_{ik}+\lambda_k\Phi_{ik}}}{\sum_{l=1}^{K}e^{W_{il}+\lambda_l\Phi_{il}}}$$

where the *inclusive value* takes the form

$$\Phi_{ik}=ln\sum_{m\epsilon B_k}e^{\frac{Y_{im}}{\lambda_k}}$$
and $P_{ij|B_k}$ denotes the probability of person *i* choosing alternative *j* conditioned on choosing nest *k*

$$P_{ij|B_k}=\frac{e^{\frac{Y_{ij}}{\lambda_k}}}{\sum_{m\epsilon B_k}e^{\frac{Y_{im}}{\lambda_k}}}$$
  a) Here, I use algebra to demonstrate that the nested logit model reduces to the multinomial logit model if $\lambda_k=1$ for all *k* - the alternatives within every nest are independent of each other. We start with the nested logit choice probability:
  
$$P_{ij}=P_{iB_k}\times P_{ij|B_k}$$
$$P_{ij}=\frac{e^{W_{ik}+\lambda_k\Phi_{ik}}}{\sum_{l=1}^{K}e^{W_{il}+\lambda_l\Phi_{il}}}\times\frac{e^{\frac{Y_{ij}}{\lambda_k}}}{\sum_{m\epsilon B_k}e^{\frac{Y_{im}}{\lambda_k}}}$$
$$P_{ij}=\frac{e^{W_{ik}+\lambda_kln\sum_{m\epsilon B_k}e^{\frac{Y_{im}}{\lambda_k}}}}{\sum_{l=1}^{K}e^{W_{il}+\lambda_lln\sum_{m\epsilon B_k}e^{\frac{Y_{im}}{\lambda_k}}}}\times\frac{e^{\frac{Y_{ij}}{\lambda_k}}}{\sum_{m\epsilon B_k}e^{\frac{Y_{im}}{\lambda_k}}}$$

  *Note:* $e^{x+cln(b)}=e^xe^{cln(b)}=e^xe^{lnb^c}=e^xb^c$


$$P_{ij}=\frac{e^{W_{ik}}\left[\sum_{m\epsilon B_k}e^{\frac{Y_{im}}{\lambda_k}}\right]^{\lambda_k}}{\sum_{l=1}^ke^{W_{il}}\left[\sum_{m\epsilon B_k}e^{\frac{Y_{im}}{\lambda_l}}\right]^{\lambda_l}}\times\frac{e^{\frac{Y_{ij}}{\lambda_k}}}{\sum_{m\epsilon B_k}e^{\frac{Y_{im}}{\lambda_k}}}\times\frac{e^{\frac{W_{ik}}{\lambda_k}}}{e^{\frac{W_{ik}}{\lambda_k}}}$$
$$P_{ij}=\frac{\left[\sum_{m\epsilon B_k}e^{\frac{W_{ik}+Y_{im}}{\lambda_k}}\right]^{\lambda_k}}{\sum_{l=1}^k\left[\sum_{m\epsilon B_k}e^{\frac{W_{il}+Y_{im}}{\lambda_l}}\right]^{\lambda_l}}\times\frac{e^{\frac{W_{ik}+Y_{ij}}{\lambda_k}}}{\sum_{m\epsilon B_k}e^{\frac{W_{ik}+Y_{im}}{\lambda_k}}}$$

  *Note:* $W_{ik}+Y_{ij}=V_{ik}$
  
$$P_{ij}=\frac{\left[\sum_{m\epsilon B_k}e^{\frac{V_{im}}{\lambda_k}}\right]^{\lambda_k}}{\sum_{l=1}^k\left[\sum_{m\epsilon B_k}e^{\frac{V_{im}}{\lambda_l}}\right]^{\lambda_l}}\times\frac{e^{\frac{V_{ik}}{\lambda_k}}}{\sum_{m\epsilon B_k}e^{\frac{V_{im}}{\lambda_k}}}$$
$$P_{ij}=\frac{e^{\frac{V_{ik}}{\lambda_k}}\left[\sum_{m\epsilon B_k}e^{\frac{V_{im}}{\lambda_k}}\right]^{\lambda_k-1}}{\sum_{l=1}^k\left[\sum_{m\epsilon B_k}e^{\frac{V_{im}}{\lambda_l}}\right]^{\lambda_l}}$$
  If we set $\lambda_k=1$, we get
  
$$P_{im}=\frac{e^{V_{ik}}}{\sum_me^{V_{im}}}$$
  which is the choice probability for the multinomial logit.
  
  b) Then, I show that the nested logit model also reduces to the multinomial logit model if all the nests $B_k$ $(\forall k)$ are singletons, i.e., each choice alternative is contained in its own nest.

![Reduction to singleton nests](nesting_choices.png)
  
  Consider a discrete choice model in which each nest contains one choice (Figure 1). This means that when looking at $P_{ij}$ as derived in part a), we can see that the within-nest summation, $\sum_{m\epsilon B_k}$, is actually only summing over one variable, rendering the summation symbol unnecessary. That is,
  
$$P_{ij}=\frac{e^{\frac{V_{ik}}{\lambda_k}}\left[\sum_{m\epsilon B_k}e^{\frac{V_{im}}{\lambda_k}}\right]^{\lambda_k-1}}{\sum_{l=1}^k\left[\sum_{m\epsilon B_k}e^{\frac{V_{im}}{\lambda_l}}\right]^{\lambda_l}}$$
  reduces to
  
$$P_{ij}=\frac{e^{\frac{V_{ik}}{\lambda_k}}\left[e^{\frac{V_{im}}{\lambda_k}}\right]^{\lambda_k-1}}{\sum_{l=1}^k\left[e^{\frac{V_{il}}{\lambda_l}}\right]^{\lambda_l}}$$
$$P_{ij}=\frac{e^{\frac{V_{ik}}{\lambda_k}}\left[e^\frac{V_{ik}\lambda_k-V_{ik}}{\lambda_k}\right]}{\sum_{l=1}^{k}e^{V_{il}}}$$
$$P_{ij}=\frac{e^{\frac{V_{ik}}{\lambda_k}}e^{V_{ik}}e^{-\frac{V_{ik}}{\lambda_k}}}{\sum_{l=1}^{k}e^{V_{il}}}$$
$$P_{ik}=\frac{e^{V_{ik}}}{\sum_{l=1}^{k}e^{V_{il}}}$$

  which is the choice probability for the multinomial logit.

\newpage 

##### **Problem 2.**

The file **count.dta**, which is taken from Gurmu (1997), contains data for 485 household heads who may or may not have visited a doctor during a certain period of time. The variables in the model are:

```{r estimates, echo=FALSE, message=FALSE, fig.align="center"}
tibble(" "       = c("nkids", "", "access", "", "status", "", "cons", ""),
       "Poisson" = c("-0.176***", "(0.032)", "0.937***", "(0.193)", "0.290***", "(0.018)", "0.375***", "(0.110)"),
       "NB1"     = c("-0.108**", "(0.050)", "0.537", "(0.332)", "0.264***", "(0.033)", "0.417**", "(0.186)"),
       "NB2"     = c("-0.171***", "(0.058)", "0.420", "(0.373)", "0.315***", "(0.052)", "0.561***", "(0.212)")) %>%
kable(caption = "Estimates", digits = 3)
```

```{r mfx, echo=FALSE, message=FALSE, fig.align="center"}
tibble(" "       = c("nkids", "", "access", "", "status", ""),
       "Poisson" = c("-0.283***", "(0.052)", "1.509***", "(0.315)", "0.467***", "(0.034)"),
       "NB1"     = c("-0.174**", "(0.082)", "0.865", "(0.538)", "0.426***", "(0.061)"),
       "NB2"     = c("-0.278***", "(0.100)", "0.685", "(0.608)", "0.515***", "(0.112)")) %>%
kable(caption = "Marginal Effects", digits = 3)
```

```{r overdispersion, echo=FALSE, message=FALSE, fig.align="center"}
tibble("test"      = c("Rule of Thumb", "Auxiliary Regression", "NB1 Delta", "NB2 Alpha"),
       "value" = c("6.956", "2.175", "3.088", "1.810"),
       "std. error" = c("-", "0.597", "0.404", "0.201"),
       "statistic" = c("-", "3.64", "601.24", "599.61"),
       "distribution" = c("-", "Student's t", "Chi-square", "Chi-square"),
       "p. value" = c("-", "0.000", "0.000", "0.000")) %>%
kable(caption = "Overdispersion Test Results", digits = 3)
```

\newpage  

``` {r session, echo = FALSE}
sessionInfo()
```



